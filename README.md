ğŸ¥ Dolo â€” AI-Powered Medical Report Analyzer

AI middleware backend that analyzes medical report images + lab values using Google Gemini 2.5 Flash (Vision + Text) and returns structured, clinically readable JSON responses with severity levels and recommendations.

Built with FastAPI + PostgreSQL + SQLAlchemy and designed for clean AI memory handling and production deployment.

âœ¨ Features

ğŸ§  Multi-turn AI conversation memory

ğŸ–¼ï¸ Medical report image analysis (Vision model)

ğŸ“Š Structured JSON clinical outputs

âš ï¸ Severity classification (low / medium / high)

ğŸ§ª Recommended follow-up tests

ğŸ’¡ Lifestyle suggestions

ğŸ—‚ï¸ Conversation + report history storage

ğŸ”’ Clean architecture with service layer separation

ğŸ› ï¸ Tech Stack
Layer	Tool
Backend Framework	FastAPI
Database	PostgreSQL (Neon)
ORM	SQLAlchemy
AI Model	Google Gemini 2.5 Flash
Image Handling	Base64 encoding
Environment Config	python-dotenv

ğŸ—ï¸ System Architecture
User uploads image

â†“

Backend receives file (FastAPI)

â†“

Validates type + size â†’ Saves to disk + DB

â†“

Converts to base64 â†’ Builds context:

â†’ System prompt (guardrails + JSON format)

â†’ Memory prompt (conversation continuity)

â†’ Last 10 messages from DB

â†’ New user message + image

â†“

Sends to Google Gemini 2.5 Flash (temp=0.2)

â†“

Stores AI response in PostgreSQL

â†“

Returns structured JSON to client

ğŸ“ Project Structure
backend/

â”œâ”€â”€ [main.py](http://main.py)                 # FastAPI app + CORS + error handling

â”œâ”€â”€ [config.py](http://config.py)               # Environment variable loader

â”œâ”€â”€ [database.py](http://database.py)             # SQLAlchemy engine + session

â”œâ”€â”€ models/

â”‚   â”œâ”€â”€ [conversation.py](http://conversation.py)     # Conversation model

â”‚   â”œâ”€â”€ [message.py](http://message.py)          # Message model

â”‚   â””â”€â”€ [report.py](http://report.py)           # Report (stored images) model

â”œâ”€â”€ schemas/

â”‚   â””â”€â”€ [schemas.py](http://schemas.py)          # Pydantic request/response schemas

â”œâ”€â”€ routers/

â”‚   â”œâ”€â”€ [conversation.py](http://conversation.py)     # Conversation CRUD endpoints

â”‚   â””â”€â”€ [analyze.py](http://analyze.py)          # Text chat + image analysis endpoints

â”œâ”€â”€ services/

â”‚   â”œâ”€â”€ ai_[service.py](http://service.py)       # Gemini API integration (text + vision)

â”‚   â””â”€â”€ memory_[service.py](http://service.py)   # Context builder + message storage

â”œâ”€â”€ utils/

â”‚   â””â”€â”€ [prompts.py](http://prompts.py)          # System + memory prompt templates

â”œâ”€â”€ uploads/                # Stored report images

â”œâ”€â”€ requirements.txt

â””â”€â”€ .env                    # API keys (not committed)

ğŸ“¡ API Endpoints
ğŸ©º Health Check
GET /health
{
  "status": "ok",
  "service": "Dolo AI Backend",
  "version": "1.0.0"
}
ğŸ’¬ Create Conversation
POST /conversation/
{
  "title": "Blood Test Analysis"
}

Response:

{
  "id": 1,
  "title": "Blood Test Analysis",
  "created_at": "...",
  "messages": []
}
ğŸ“– Get Conversation
GET /conversation/{conversation_id}

Returns full conversation history including stored AI responses.

ğŸ§  Text Chat (With Memory)
POST /chat/{conversation_id}
{
  "message": "My hemoglobin is 10.2 g/dL and WBC is 12,500. Is this normal?"
}

Response:

{
  "conversation_id": 1,
  "response": {
    "summary": "Mildly low hemoglobin with elevated WBC count",
    "abnormal_findings": [
      {
        "parameter": "Hemoglobin",
        "value": "10.2 g/dL",
        "normal_range": "12-16 g/dL",
        "severity": "medium"
      },
      {
        "parameter": "WBC",
        "value": "12,500",
        "normal_range": "4,500-11,000",
        "severity": "low"
      }
    ],
    "recommended_tests": [
      "Iron studies",
      "Peripheral blood smear"
    ],
    "lifestyle_suggestions": [
      "Increase iron-rich foods",
      "Follow up in 2 weeks"
    ],
    "urgency": "medium"
  }
}
ğŸ–¼ï¸ Image Analysis
POST /analyze-report/{conversation_id}

Content-Type: multipart/form-data

file: medical report image

message: optional text prompt

Example:

file: blood_test.jpg
message: "Analyze this blood test report"

Response:

{
  "conversation_id": 1,
  "report_id": 1,
  "filename": "blood_test.jpg",
  "file_url": "/uploads/1708123456_blood_test.jpg",
  "response": {
    "summary": "...",
    "abnormal_findings": [...],
    "recommended_tests": [...],
    "lifestyle_suggestions": [...],
    "urgency": "medium"
  }
}
ğŸ—‚ï¸ Get Reports for a Conversation
GET /conversation/{conversation_id}/reports

Returns all uploaded medical reports linked to that conversation.

ğŸš€ Run Locally
Prerequisites

Python 3.10+

PostgreSQL database (e.g., Neon)

Google Gemini API key

1ï¸âƒ£ Clone Repository
git clone https://github.com/your-username/dolo-backend.git
cd dolo-backend/backend
2ï¸âƒ£ Create Virtual Environment
python -m venv venv
source venv/bin/activate      # Mac/Linux
venv\Scripts\activate         # Windows
3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt
4ï¸âƒ£ Configure Environment Variables

Create a .env file:

DATABASE_URL=postgresql://username:password@host/dbname
GEMINI_API_KEY=your_google_gemini_api_key
5ï¸âƒ£ Run Server
uvicorn main:app --reload

Server runs at:

http://localhost:8000

Swagger docs available at:

http://localhost:8000/docs
ğŸ” AI Design Principles

Deterministic output (temperature = 0.2)

Strict JSON schema enforcement

Medical safety guardrails in system prompt

Limited memory window (last 10 messages)

Clean separation between AI service and memory service

ğŸ“Œ Future Improvements

Role-based authentication

PDF report support

Structured lab reference ranges by region

Redis caching for context building

Deployment on Render / Railway

Frontend dashboard (React)

âš ï¸ Disclaimer

Dolo is an AI-assisted medical interpretation tool.
It does not replace professional medical diagnosis.
Users must consult licensed healthcare providers for medical decisions.

ğŸ§‘â€ğŸ’» Author

Built with precision and structured architecture for production-ready AI middleware.
